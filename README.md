# Ball Catching Robot
 Built a robot that computes 3D location of the ball using Monocular camera, predicts the trajectory and catches the ball in middle of its trajectory

 ![Experiment Setup ....loading](https://github.com/venkydesai/ball_catching_robot/blob/main/images/Robotic_arm_ball_3.jpeg)

 This project is aimed to develop a system capable of tracking and touching a dynamically moving ball using a robotic arm guided by computer vision techniques. The primary challenge involved using a monocular camera, which provides only 2D image coordinates, necessitating the estimation of 3D coordinates for accurate trajectory prediction and robotic control. Initially, a color-based segmentation approach using HSV masks was explored for ball detection but proved less accurate under varying lighting conditions. Subsequently, the state-of-the-art YOLOv8 object detection model was employed, leveraging its robust performance in localizing and tracking the ball across video frames. The 3D coordinates of the detected ball were estimated using the `cv2.solvePnP` function in OpenCV, and ArUco markers were strategically placed in the scene to establish the required poses and coordinate system alignments. By integrating these computer vision techniques with physics-based trajectory prediction models, the system demonstrated the capability to track and touch a ball rolling on the floor, showcasing the synergy between computer vision, trajectory estimation, and robotic manipulation for precise and dynamic interactions with moving objects.

